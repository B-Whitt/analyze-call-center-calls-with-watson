{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Call Center Analytics using Waston AI Services\n\nThis notebook shows some analytics that you can run against the enriched data of the call center messages to extract insights such as keywords most referenced in the calls, the overall sentiment aggregated over a number of calls, the most dominant tones in the conversations and how a tone evolves over an interaction with a user during a call.", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## Table of contents\n\n1. [Load the required libraries](#loadlibraries)\n2. [Setup Access to your Cloud Object Storage instance](#loaddata)\n3. [Visualize Sentiment and Top Keywords using Watson NLU response](#visualizeNLU)\n4. [Visualize Emotion Tone using Watson Tone Analyzer response](#visualizeToneAnalyzer)\n5. [Summary](#summary)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"loadlibraries\"></a>\n## Step 1: Load the required libraries\n\nLoad several Python libraries for analytics and visualization.\n- <a href=\"https://github.com/amueller/word_cloud/\" target=\"_blank\" rel=\"noopener no referrer\">wordcloud</a> is a Python library for generating Word Clouds \n- <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_blank\">PixieDust</a> is a productivity tool for Python or Scala notebooks, which lets a developer encapsulate business logic into something easy for your customers to consume.>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Run pip install only the first time, once installed on your Spark machine, no need to re-run unless you want to upgrade\n!pip install --upgrade --force-reinstall wordcloud\n!pip install --user --upgrade pixiedust"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import ibm_boto3\nfrom botocore.client import Config\nimport json\nimport pixiedust\nfrom pixiedust.display import *\n\nimport requests\n\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import StringType\n\nimport matplotlib.pyplot as plt\n\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import col"
        }, 
        {
            "source": "<a id=\"loaddata\"> </a>\n## Step 2: Setup Access to your Cloud Object Storage instance\n\nThe first step is to load the data. This notebook assumes you have your enriched data stored in cloud object storage. In particular, we load the Watson Natural Language Understanding response for call center logs from cloud object storage.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "endpoints = requests.get(credentials_os['endpoints']).json()\n\niam_host = (endpoints['identity-endpoints']['iam-token'])\ncos_host = (endpoints['service-endpoints']['cross-region']['us']['public']['us-geo'])\n\nauth_endpoint = \"https://\" + iam_host + \"/oidc/token\"\nservice_endpoint = \"https://\" + cos_host\n\n\nclient = ibm_boto3.client(\n    's3',\n    ibm_api_key_id = credentials_os['apikey'],\n    ibm_service_instance_id = credentials_os['resource_instance_id'],\n    ibm_auth_endpoint = auth_endpoint,\n    config = Config(signature_version='oauth'),\n    endpoint_url = service_endpoint\n   )"
        }, 
        {
            "source": "<a id=\"visualizeNLU\"></a>\n## Step 3: Visualize Sentiment and Top Keywords using Watson NLU response\nDefine the function to parse Watson NLU json response and extract sentiment score, sentiment label, and keywords.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Method to parse NLU response file from Cloud Object Storage\n# and return sentiment score, sentiment label, and keywords\n# This method works for the scenario of one NLU call per call (file)\ndef getNLUresponse(COSclient, bucket, files):\n    nlu_results = []\n    for filename in files:\n        # Extract NLU enriched filename from the original file name\n        nlu_filename = filename.split('.')[0]+'_NLU.json'\n        print(\"Processing NLU response from file: \", nlu_filename)\n        streaming_body = COSclient.get_object(Bucket=bucket, Key=nlu_filename)['Body']\n        nlu_response = json.loads(streaming_body.read().decode(\"utf-8\"))\n        #print(json.dumps(nlu_response,indent=2))\n        if nlu_response and nlu_response['sentiment'] \\\n        and nlu_response['sentiment']['document'] and nlu_response['sentiment']['document']['label']:\n            sentiment_score = nlu_response['sentiment']['document']['score']\n            sentiment_label = nlu_response['sentiment']['document']['label']\n            keywords = list(nlu_response['keywords'])\n        else:\n            sentiment_score = 0.0\n            sentiment_label = None\n            keywords = null\n        nlu_results.append((filename,sentiment_score,sentiment_label,keywords))\n    return (nlu_results)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "\n# Method to parse NLU Emotion Tone response file from Cloud Object Storage\ndef getChunkNLU(nlu_response):\n    #print(json.dumps(nlu_response,indent=2))\n    if nlu_response and nlu_response['sentiment'] \\\n    and nlu_response['sentiment']['document'] and nlu_response['sentiment']['document']['label']:\n        sentiment_score = nlu_response['sentiment']['document']['score']\n        sentiment_label = nlu_response['sentiment']['document']['label']\n        keywords = list(nlu_response['keywords'])\n    else:\n        sentiment_score = 0.0\n        sentiment_label = None\n        keywords = null\n    \n    return sentiment_score, sentiment_label, keywords\n\n# Method to parse NLU response file from Cloud Object Storage\n# and return sentiment score, sentiment label, and keywords\n# This method handles the scenario when call is broken into multiple chunks\ndef getNLUresponseChunks(COSclient, bucket, files):\n    nlu_results = []\n    print(\"files: \", files)\n    for filename in files:\n        # Extract NLU enriched filename from the original file name\n        nlu_filename = filename.split('.')[0]+'_NLUchunks.json'\n        print(\"Processing NLU response from file: \", nlu_filename)\n        streaming_body = COSclient.get_object(Bucket=bucket, Key=nlu_filename)['Body']\n        nlu_chunks_response = json.loads(streaming_body.read().decode(\"utf-8\"))\n        if nlu_chunks_response and len(nlu_chunks_response)>0:\n            chunkidx = 0\n            for chunk in nlu_chunks_response:\n                chunk_nlu = getChunkNLU(nlu_chunks_response[chunk])\n                print('chunk nlu: ', chunk_nlu)\n                print('type of chunk nlu: ', type(chunk_nlu))\n                chunkidx = chunkidx + 1\n                tmp_results = (filename, chunkidx, chunk_nlu)\n                print('tmp results: ', tmp_results)\n                print('length of tmp results: ', len(tmp_results))\n                l = list((filename,chunkidx)) + list(chunk_nlu)\n                print('len of l: ', len(l))\n                nlu_results.append(l)\n               # nlu_results.append((filename, chunkidx, chunk_nlu))\n        \n    return (nlu_results)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# List of files which were transcribed by STT and enriched with NLU\nfile_list = ['sample1-addresschange-positive.ogg',\n             'sample2-address-negative.ogg',\n             'sample3-shirt-return-weather-chitchat.ogg',\n             'sample4-angryblender-sportschitchat-recovery.ogg',\n             'sample5-calibration-toneandcontext.ogg',\n             'jfk_1961_0525_speech_to_put_man_on_moon.ogg',\n             'May 1 1969 Fred Rogers testifies before the Senate Subcommittee on Communications.ogg']"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Specify the bucket which contains the enriched NLU files\nbucket = credentials_os['BUCKET']\n\n# Define header to map to extracted NLU features\n#nlu_header=['filename','sentiment_score','sentiment_label','keywords']\n#nlu_results = getNLUresponse(client,bucket,file_list)\n\n## Alternative call to handle the case when the NLU response has been broken into chunks of 25 words each\nnlu_header=['filename','chunkidx','sentiment_score','sentiment_label','keywords']\nnlu_results = getNLUresponseChunks(client,bucket,file_list)\n    "
        }, 
        {
            "source": "Map the parsed NLU responses into a Spark dataframe, one record for each file (if no chunking of data), where each file is the NLU response for one call center record.\nFor the case when data is chunked, each records corresponds to a unique chunk of a call center record (a chunk is defined as 25 words or so).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "callcenterlogs_nluDF = spark.createDataFrame(nlu_results, nlu_header)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "# Common validation calls to better understand your data\ncallcenterlogs_nluDF.printSchema()\ncallcenterlogs_nluDF.show()"
        }, 
        {
            "source": "### Sentiment plots using PixieDust\nLeverage PixieDust to plot sentiment labels as a pie-chart showing how many positive, negative, and neutral calls are received.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "## Ignore any records with null sentiment label\ncallcenterlogs_nluDF = callcenterlogs_nluDF.where(col('sentiment_label').isNotNull())\nperlabel_sentimentDF = callcenterlogs_nluDF.groupBy('sentiment_label')\\\n                              .agg(F.count('filename')\\\n                              .alias('num_calls'))\n\n## Take a look\nperlabel_sentimentDF.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "tableFields": "sentiment_score", 
                        "no_margin": "true", 
                        "orientation": "vertical", 
                        "title": "sentiment distribution", 
                        "chartsize": "52", 
                        "mpld3": "false", 
                        "aggregation": "COUNT", 
                        "filter": "{}", 
                        "handlerId": "pieChart", 
                        "sortby": "Keys ASC", 
                        "keyFields": "sentiment_label"
                    }
                }, 
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "# Call Pixiedust to visualize sentiment data\ndisplay(callcenterlogs_nluDF)"
        }, 
        {
            "source": "### Keywords visualization using Word Cloud\nNext, we process the NLU keywords results to understand what are the top keywords referenced in the call center interactions. This would be very helpful in delivering insights what are the main topics being referenced in these call center interactions.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.sql.functions import explode\n\n# Explode keywords\ncallcenterlogs_nluDF = callcenterlogs_nluDF.select(explode('keywords').alias('topkeywords'))\ncallcenterlogs_nluDF = callcenterlogs_nluDF.select('topkeywords').rdd.map(lambda row: row[0]).toDF()\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# check top rows\ncallcenterlogs_nluDF.head(4)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# UDF to return lower case of word\ndef toLowerCase(word):\n    return word.lower()\n\n\n# Process extracted keywords to change to lower case\nudfLowerCase = udf(toLowerCase, StringType())\ncallcenterlogsTopKeywordsDF = callcenterlogs_nluDF.withColumn('topkeywords',udfLowerCase('text'))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Group by topkeywords and compute average relevance per keyword and also number of calls for each keyword\ncallcenterlogsKwdsNumDF = callcenterlogsTopKeywordsDF.groupBy('topkeywords')\\\n                              .agg(F.count('topkeywords').alias('kwdsnumcalls'))\ncallcenterlogsKwdsRelDF = callcenterlogsTopKeywordsDF.groupBy('topkeywords')\\\n                          .agg(F.avg('relevance').alias('kwdsavgrelevance'))\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# join the keywords nunber and keywords relevance dataframes into one\ncallcenterlogsKeywordsDF = callcenterlogsKwdsNumDF.join(callcenterlogsKwdsRelDF,'topkeywords','outer')\n\n# Define keyword score as product of number of calls expressing that keyword and average relevance of that keyword\ncallcenterlogsKeywordsDF = callcenterlogsKeywordsDF.withColumn('keyword_score',callcenterlogsKeywordsDF.kwdsnumcalls * callcenterlogsKeywordsDF.kwdsavgrelevance)\n\n# Sort dataframe in descending order of KEYWORD_SCORE\ncallcenterlogsKeywordsDF = callcenterlogsKeywordsDF.orderBy('keyword_score',ascending=False)\n\n# Remove None keywords\ncallcenterlogsKeywordsDF = callcenterlogsKeywordsDF.where(col('topkeywords').isNotNull())\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "print(\"Top Keywords from call center logs\")\ncallcenterlogsKeywordsDF.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "filter": "{\"value\": \"0.8\", \"regex\": \"False\", \"field\": \"kwdsavgrelevance\", \"constraint\": \"greater_than\", \"case_matter\": \"False\"}", 
                        "handlerId": "pieChart", 
                        "no_margin": "true", 
                        "orientation": "horizontal", 
                        "valueFields": "kwdsnumcalls", 
                        "keyFields": "topkeywords"
                    }
                }, 
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "# visualize top keywords with pixiedust\ndisplay(callcenterlogsKeywordsDF)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Map to Pandas DataFrame\ncallcenterlogsKeywordsPandas = callcenterlogsKeywordsDF.toPandas()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from wordcloud import WordCloud\n\n# Process Pandas DataFrame in the right format to leverage wordcloud.py for plotting\n# See documentation: https://github.com/amueller/word_cloud/blob/master/wordcloud/wordcloud.py \ndef prepForWordCloud(pandasDF,n):\n    kwdList = pandasDF['topkeywords']\n    sizeList = pandasDF['keyword_score']\n    kwdSize = {}\n    for i in range(n):\n        kwd=kwdList[i]\n        size=sizeList[i]\n        kwdSize[kwd] = size\n    return kwdSize"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {}
                }
            }, 
            "outputs": [], 
            "source": "%matplotlib inline\nmaxWords = len(callcenterlogsKeywordsPandas)\nnWords = 20\n\n#Generating wordcloud. Relative scaling value is to adjust the importance of a frequency word.\n#See documentation: https://github.com/amueller/word_cloud/blob/master/wordcloud/wordcloud.py\ncallcenterlogsKwdFreq = prepForWordCloud(callcenterlogsKeywordsPandas,nWords)\ncallcenterlogsWordCloud = WordCloud(max_words=maxWords,relative_scaling=0,normalize_plurals=False).generate_from_frequencies(callcenterlogsKwdFreq)\n\nfig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (15,15))\nax.imshow(callcenterlogsWordCloud)\n\n# turn off axis and ticks\nplt.axis(\"off\")\n\n\nplt.show()"
        }, 
        {
            "source": "<a id=\"visualizeToneAnalyzer\"></a>\n## Step 4: Visualize Emotion Tone using Watson Tone Analyzer response\nDefine the function to parse Watson Tone Analyzer json response and extract emotion tone labels and scores.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Method to parse NLU Emotion Tone response file from Cloud Object Storage\ndef getChunkTone(tone_categories):\n    for category in tone_categories:\n        if category['category_id'] == 'emotion_tone':\n            tones = category['tones']\n    return (tones)\n\ndef getTAresponse(COSclient, bucket, files):\n    tone_results=[]\n    for filename in files:        \n        tone_filename = filename.split('.')[0]+'_tone.json'\n        print(\"Processing Tone Analyzer response from file: \", tone_filename)\n        streaming_body = COSclient.get_object(Bucket=bucket, Key=tone_filename)['Body']\n        ta_response = json.loads(streaming_body.read().decode(\"utf-8\"))\n        if ta_response and len(ta_response)>0:\n            chunkidx=0\n            for chunk in ta_response:\n                chunk_tones = getChunkTone(ta_response[chunk]['document_tone']['tone_categories'])\n                chunkidx = chunkidx + 1\n                tone_results.append((filename, chunkidx, chunk_tones))\n    return (tone_results)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# original list of audio files\nfile_list = ['sample1-addresschange-positive.ogg',\n             'sample2-address-negative.ogg',\n             'sample3-shirt-return-weather-chitchat.ogg',\n             'sample4-angryblender-sportschitchat-recovery.ogg',\n             'sample5-calibration-toneandcontext.ogg',\n             'jfk_1961_0525_speech_to_put_man_on_moon.ogg',\n             'May 1 1969 Fred Rogers testifies before the Senate Subcommittee on Communications.ogg']"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Get the emotion tones for all the audio files\nta_header=['filename','chunkindex','tones']\nta_results=getTAresponse(client,bucket,file_list)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Create a Spark dataframe based on the extracted emotion tones\ncallcenterlogs_taDF = spark.createDataFrame(ta_results, ta_header)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Print top rows\ncallcenterlogs_taDF.head(4)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "callcenterlogs_taDF.printSchema()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# If not imported earlier, import explode\nfrom pyspark.sql.functions import explode\n\n# Explode tones\ncallcenterlogs_taDF_tones = callcenterlogs_taDF.select(explode('tones').alias('toptones'))\ncallcenterlogs_taDF_tones = callcenterlogs_taDF_tones.select('toptones').rdd.map(lambda row: row[0]).toDF()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Print schema and note that score is of type string\ncallcenterlogs_taDF_tones.printSchema()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Cast the score column from String to Double\ncallcenterlogs_taDF_tones = callcenterlogs_taDF_tones.withColumn(\"score\", col(\"score\").cast(\"double\"))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Print schema to verify score is now of type double\ncallcenterlogs_taDF_tones.printSchema()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "callcenterlogs_taDF_tones.head(5)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "callcenterlogs_taDF.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "callcenterlogs_taDF.printSchema()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# If not imported earlier, import explode\nfrom pyspark.sql.functions import explode\n\n# Explode tones\ncallcenterlogs_taDF = callcenterlogs_taDF.withColumn('toptones',explode('tones'))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "callcenterlogs_taDF.printSchema()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "callcenterlogs_taDF.head(5)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Select only the columns of interest\ncallcenterlogs_taDF_v1 = callcenterlogs_taDF.select('filename','chunkindex','toptones')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "callcenterlogs_taDF_v1.head(6)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Flatten nested fields\ncallcenterlogs_taDF_v2 = callcenterlogs_taDF_v1.select(F.col(\"filename\").alias(\"filename\"),F.col(\"chunkindex\").alias(\"chunkindex\"), F.col(\"toptones.tone_name\").alias(\"tone_name\"), F.col(\"toptones.tone_id\").alias(\"tone_id\"), F.col(\"toptones.score\").alias(\"score\"))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "callcenterlogs_taDF_v2.printSchema()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Cast the score column from String to Double\ncallcenterlogs_taDF_v2 = callcenterlogs_taDF_v2.withColumn(\"score\", col(\"score\").cast(\"double\"))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "callcenterlogs_taDF_v2.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Group by toptones and compute average score per tone and also number of calls for each tone\ncallcenterlogsTonesNumDF = callcenterlogs_taDF_v2.groupBy('tone_id')\\\n                           .agg(F.count('tone_id').alias('tonesnumcalls'))\ncallcenterlogsTonesScoreDF = callcenterlogs_taDF_v2.groupBy('tone_id')\\\n                          .agg(F.avg('score').alias('tonesavgscore'))\n    "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# join the tones nunber and tones scores dataframes into one\ncallcenterlogsTonesDF = callcenterlogsTonesNumDF.join(callcenterlogsTonesScoreDF,'tone_id','outer')\n\n# Define tones score as product of number of calls expressing that tone and average score of that tone\ncallcenterlogsTonesDF = callcenterlogsTonesDF.withColumn('tones_score',callcenterlogsTonesDF.tonesnumcalls * callcenterlogsTonesDF.tonesavgscore)\n\n# Sort dataframe in descending order of tones_score\ncallcenterlogsTonesDF = callcenterlogsTonesDF.orderBy('tones_score',ascending=False)\n\n# Remove None tones\ncallcenterlogsTonesDF = callcenterlogsTonesDF.where(col('tone_id').isNotNull())"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "callcenterlogsTonesDF.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Translate spark dataframe into Pandas dataframe for plotting\ncallcenterlogsTonesPandas = callcenterlogsTonesDF.toPandas()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import numpy as np\n\ntone_labels = callcenterlogsTonesPandas['tone_id']\ntone_values = callcenterlogsTonesPandas['tonesavgscore']\nxindices = np.arange(len(tone_values))\n\nm = tone_values.max()\nstart=0.0\nstop=m+0.2\nstep=0.1\nyindices = np.arange(start,stop,step)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "## Plot bar chart of top tones aggregated across all calls\nfig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 15))\n\naxes.set_xticks(xindices)\naxes.set_xticklabels(tone_labels)\naxes.set_xlabel('Tones')\naxes.set_yticks(yindices)\naxes.set_ylabel('Average Tone Score')\n#axes.bar(xindices, tone_values, align='center', alpha=0.5)\naxes.bar(xindices, tone_values)\n\naxes.set_title('Emotion Tone aggregated over all calls')\n\nplt.show()"
        }, 
        {
            "source": "## Emotion Tone over call duration\nNext, we plot the emotion tone over the duration of one call to visualize how the tone changes during the call.\nFor that purpose, we select a specific file 'sample7-FredRogers' and plot the various tones over chunks of the interaction, each chunk representing 25 words.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "# Print the callcenterlogs_taDF_v2 which included the expanded tones per file and chunk\ncallcenterlogs_taDF_v2.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Next we filter the data to return only the tones for the reference file name we're interested in\nfilename = file_list[6]\n#filename = \"'\" + filename + \"'\"\nprint('filtering by filename: ', filename)\ncallcenterlogs_taDF_v3 = callcenterlogs_taDF_v2.where(col('filename') == filename)\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# verify how many records exist\ncallcenterlogs_taDF_v3.count()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "callcenterlogs_taDF_v3.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Filter the tones per tone_id so we can plot each tone separately\ncallcenterlogs_taDF_anger = callcenterlogs_taDF_v3.where(col('tone_id') == 'anger')\ncallcenterlogs_taDF_disgust = callcenterlogs_taDF_v3.where(col('tone_id') == 'disgust')\ncallcenterlogs_taDF_fear = callcenterlogs_taDF_v3.where(col('tone_id') == 'fear')\ncallcenterlogs_taDF_joy = callcenterlogs_taDF_v3.where(col('tone_id') == 'joy')\ncallcenterlogs_taDF_sadness = callcenterlogs_taDF_v3.where(col('tone_id') == 'sadness')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "callcenterlogs_taDF_anger.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# convert spark dataframe to pandas for plotting\ncallcenterlogs_taDF_anger = callcenterlogs_taDF_anger.toPandas()\ncallcenterlogs_taDF_disgust = callcenterlogs_taDF_disgust.toPandas()\ncallcenterlogs_taDF_fear = callcenterlogs_taDF_fear.toPandas()\ncallcenterlogs_taDF_joy = callcenterlogs_taDF_joy.toPandas()\ncallcenterlogs_taDF_sadness = callcenterlogs_taDF_sadness.toPandas()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Prepare the data for plotting\nx = callcenterlogs_taDF_anger['chunkindex']\nanger_tone = callcenterlogs_taDF_anger['score']\ndisgust_tone = callcenterlogs_taDF_disgust['score']\nfear_tone = callcenterlogs_taDF_fear['score']\njoy_tone = callcenterlogs_taDF_joy['score']\nsadness_tone = callcenterlogs_taDF_sadness['score']"
        }, 
        {
            "source": "**Optional** Next cell is optional, it plots the different tones as lines over time, where time is measured in terms of chunks of words (each chunk is 25 words or so).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "# Plot line chart for the different tones\nfig, axes = plt.subplots(nrows=1, ncols=1, figsize=(30, 30))\naxes.plot(x, anger_tone, linewidth=2, color='purple')\naxes.plot(x, disgust_tone, linewidth=2, color='yellow')\naxes.plot(x, fear_tone, linewidth=2, color='red')\naxes.plot(x, joy_tone, linewidth=2, color='blue')\naxes.plot(x, sadness_tone, linewidth=2, color='green')\n\naxes.set_xticks(x.index.tolist())\n\naxes.set_xlabel('Chunk index')\naxes.set_ylabel('Tone score')\naxes.set_title('Tone variation over time')\naxes.legend(loc=\"upper right\", labels=['anger','disgust','fear','joy','sadness'])\nplt.show()"
        }, 
        {
            "source": "**Stacked Bar Plot** Next we plot the different emotion tones in the form of stacked bar over time, where time is measure in terms of chunks of words.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "\nfig, axes = plt.subplots(nrows=1, ncols=1, figsize=(30, 20))\nwidth=0.3\naxes.bar(x, anger_tone, width, color='blue', align='center', alpha=0.5)\naxes.bar(x, disgust_tone, width, color='red', align='center', alpha=0.5, bottom=anger_tone)\naxes.bar(x, fear_tone, width, color='green', align='center', alpha=0.5, bottom=(anger_tone + disgust_tone))\naxes.bar(x, joy_tone, width, color='yellow', align='center', alpha=0.5, bottom=(anger_tone + disgust_tone + fear_tone))\naxes.bar(x, sadness_tone, width, color='purple', align='center', alpha=0.5, bottom=(anger_tone + disgust_tone + fear_tone + joy_tone))\n\naxes.set_xticks(x.index.tolist())\n\naxes.set_xlabel('Time (Chunk index)')\naxes.set_ylabel('Emotion Tone score')\naxes.set_title('Emotion Tone variation over time')\naxes.legend(loc=\"upper right\", labels=['anger','disgust','fear','joy','sadness'])\n\nplt.show()"
        }, 
        {
            "source": "## Call Center Analytics Dashboard \nLastly, we bring all the results together into one dashboard. Specifically, we plot 4 relevant pieces of information extracted from the analysis of the transcribed and enriched audio calls, nam", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "perlabelSentimentDF = perlabel_sentimentDF.toPandas()\n\nsentiment_labels = perlabelSentimentDF['sentiment_label']\nsentiment_values = perlabelSentimentDF['num_calls']\nsentiment_colors = ['green', 'gray', 'red']\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%matplotlib inline\nmaxWords = len(callcenterlogsKeywordsPandas)\nnWords = 15\n\n#Generating wordcloud. Relative scaling value is to adjust the importance of a frequency word.\n#See documentation: https://github.com/amueller/word_cloud/blob/master/wordcloud/wordcloud.py\n# These variables should be computed already earlier in the notebook. If not, uncomment the next two\n# lines and re-run\n##callcenterlogsKwdFreq = prepForWordCloud(callcenterlogsKeywordsPandas,nWords)\n##callcenterlogsWordCloud = WordCloud(max_words=maxWords,relative_scaling=0,normalize_plurals=False).generate_from_frequencies(callcenterlogsKwdFreq)\n\n\n# Create a 2x2 dashboard with 4 plots\nfig, ax = plt.subplots(nrows = 2, ncols = 2, figsize = (30, 30))\n\n## Set titles for images\nax[0,0].set_title('Top Keywords (aggregated across call logs)')\nax[0,1].set_title('Overall Sentiment (aggregated across call logs)')\nax[1,0].set_title('Top Emotion Tones(aggregated across call logs)')\nax[1,1].set_title('Emotion Tone Variation over Time (largest sample call log)')\n\n                \n## Plot word cloud of top keywords aggregated over all calls\nax[0,0].imshow(callcenterlogsWordCloud)\n\n## Plot pie chart of the sentiment aggregated across all calls\nax[0,1].pie(sentiment_values, labels = sentiment_labels, colors = sentiment_colors, autopct = '%1.1f%%')\n\n## Plot bar chart of top tones aggregated across all calls\nax[1,0].set_xticks(xindices)\nax[1,0].set_xticklabels(tone_labels)\nax[1,0].set_xlabel('Tones')\nax[1,0].set_yticks(yindices)\nax[1,0].set_ylabel('Average Score')\nax[1,0].bar(xindices, tone_values, align='center', alpha=0.5)\n\n# Plot stacked bar chart for emotion tones and how they vary over the duration of one specific sample audio file\nwidth=0.3\nax[1,1].bar(x, anger_tone, width, color='blue', align='center', alpha=0.5)\nax[1,1].bar(x, disgust_tone, width, color='red', align='center', alpha=0.5, bottom=anger_tone)\nax[1,1].bar(x, fear_tone, width, color='green', align='center', alpha=0.5, bottom=(anger_tone + disgust_tone))\nax[1,1].bar(x, joy_tone, width, color='yellow', align='center', alpha=0.5, bottom=(anger_tone + disgust_tone + fear_tone))\nax[1,1].bar(x, sadness_tone, width, color='purple', align='center', alpha=0.5, bottom=(anger_tone + disgust_tone + fear_tone + joy_tone))\nax[1,1].legend(loc=\"upper right\", labels=['anger','disgust','fear','joy','sadness'])\n\n\nplt.show()\n"
        }, 
        {
            "source": "<a id=\"summary\"></a>\n## Summary\nIn this series of notebooks, we showed how you can start with audio recordings from call center interactions, leverage several Watson services to transcribe the audio into text and then enrich that text with keywords, sentiment, and emotion tone. Lastly, we ran some analytics on all these enrichments to get a better understanding of the operations of our call center.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}