{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "## Notebook 4 \u2013 Tone Analyzer \nhttps://www.ibm.com/watson/developercloud/tone-analyzer.html \nhttps://www.ibm.com/watson/developercloud/tone-analyzer/api/v3/ \n\nTone Analyzer service uses linguistic analysis to detect emotional and language tones in written text.\n\nIf you already have an IBM Cloud / Bluemix account login here https://console.bluemix.net/ \nIf you have not registered for IBM Cloud - you will need to Register for a Free account here https://www.ibm.com/watson/developer/\t\n\nTo create a TONE endpoint - https://console.bluemix.net/developer/watson/dashboard  LITE Plan for Tone is free\n\n### Tone Analyzer Signals\n\nA comma-separated list of tones for which the service is to return its analysis of the input. The indicated tones apply both to the full document and to individual sentences of the document. You can specify one or more of the following values:\n    emotion\n    language\n    social\n    \n2016-05-19: The service can return results for the following tone IDs of the different categories:\n        For the emotion category: \n            anger, \n            disgust, \n            fear, \n            joy, \n            sadness\n        For the language category: \n            analytical, \n            confident, \n            tentative\n        For the social category: \n            openness_big5, \n            conscientiousness_big5, \n            extraversion_big5, \n            agreeableness_big5,\n            emotional_range_big5\n         The service returns scores for all tones of a category, regardless of their values.\n\n    \n2017-09-21: The service can return results for the following tone IDs: anger, fear, joy, sadness, analytical, confident, and tentative. The service returns results only for tones whose scores meet a minimum threshold of 0.5.\n\nIf Tone Chat Score is used - these are the signals produced\n    sad\n    frustrated\n    satisfied\n    excited\n    polite\n    impolite\n    sympathetic\n\n\n## Install dependencies", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#imports.... Run this each time after restarting the Kernel\n#!pip install watson_developer_cloud\nimport watson_developer_cloud as watson\nimport json\nfrom botocore.client import Config\nimport ibm_boto3\nimport requests\n"
        }, 
        {
            "source": "##  Cloud Object Storage - Add Credentials & Bucket Name\nIf you've not already set up COS - please see Step 1\n\n### Credentials\nCredentials are also created for you when you create project. From service dashboard page select `Service Credentials` from left navigation menu item, and copy/paste the credentials below:\n\n### Bucket name\nBuckets are created for you when you create project. From service dashboard page select `Buckets` from left navigation menu item, and get your bucket name and copy/paste bucket name below:\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# For Cloud Object Storage - populate your own information here from \"SERVICES\" on this page, or Console Dashboard on ibm.com/cloud\n\n# From service dashboard page select Service Credentials from left navigation menu item\ncredentials_os = {\n  \"apikey\": \"\",\n  \"cos_hmac_keys\": {\n    \"access_key_id\": \"\",\n    \"secret_access_key\": \"\"\n  },\n  \"endpoints\": \"https://cos-service.bluemix.net/endpoints\",\n  \"iam_apikey_description\": \"Auto generated apikey during resource-key operation for Instance\",\n  \"iam_apikey_name\": \"\",\n  \"iam_role_crn\": \"\",\n  \"iam_serviceid_crn\": \"\",\n  \"resource_instance_id\": \"\"\n}\n\n# Buckets are created for you when you create project. From service dashboard page select Buckets from left navigation menu item, \ncredentials_os['BUCKET'] = '<bucket_name>' # copy bucket name from COS"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "source": "### Create Watson TONE Analyzer service\n\nTwo options to create a new TONE service.  (1) Above click SERVICES and create/add new LITE version of TONE; or (2) In Console Dashboard in ibm.com/cloud create a LITE TONE services.  Click on 'SERVICE CREDENTIALS' to get creds.\n\nFor more information on creating Watson services, see Notebook 1", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Add your TONE Service credentials here\ncredentials_tone = {\n    \"url\": '',\n    \"username\": '',\n    \"password\": ''\n}"
        }, 
        {
            "source": "### Set up Object Storage Client", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "endpoints = requests.get(credentials_os['endpoints']).json()\n\niam_host = (endpoints['identity-endpoints']['iam-token'])\ncos_host = (endpoints['service-endpoints']['cross-region']['us']['public']['us-geo'])\n\nauth_endpoint = \"https://\" + iam_host + \"/oidc/token\"\nservice_endpoint = \"https://\" + cos_host\n\n\nclient = ibm_boto3.client(\n    's3',\n    ibm_api_key_id = credentials_os['apikey'],\n    ibm_service_instance_id = credentials_os['resource_instance_id'],\n    ibm_auth_endpoint = auth_endpoint,\n    config = Config(signature_version='oauth'),\n    endpoint_url = service_endpoint\n   )\n\n\n\n"
        }, 
        {
            "source": "### Tone\n\n- `process_text()` goes throught the text and fetch sentences and concatenate transcript based on chunk size\n- `analyze transcript()` calls tone analyzer endpoint and analyze the transcript\n- `post_anlysis()` shows tones and their score\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from watson_developer_cloud import ToneAnalyzerV3\n\ntone_analyzer = ToneAnalyzerV3(version = '2016-05-19',\n                               username = credentials_tone['username'],\n                               password = credentials_tone['password'])\n\n\nchunk_size=25\n\ndef chunk_transcript(transcript, chunk_size):\n    transcript = transcript.split(' ')\n    return [ transcript[i:i+chunk_size] for i in range(0, len(transcript), chunk_size) ] # chunking data\n    \n\ndef process_text(text):\n    transcript=''\n    for sentence in json.loads(text)['results']:\n        transcript = transcript + sentence['alternatives'][0]['transcript'] # concatenate sentences\n    transcript = chunk_transcript(transcript, chunk_size) # chunk the transcript\n    return transcript\n\n\ndef analyze_transcript(file_name):\n    transcript = client.get_object(Bucket = credentials_os['BUCKET'], Key = file_name.split('.')[0]+'_text.json')['Body']\n    transcript = transcript.read().decode(\"utf-8\")\n    tone_analysis={}\n    for chunk in process_text(transcript):\n        if len(chunk) > 2:\n            chunk = ' '.join(chunk)\n            tone_analysis[chunk] = tone_analyzer.tone(chunk, content_type='text/plain')\n    res=client.put_object(Bucket = credentials_os['BUCKET'], Key= file_name.split('.')[0]+'_tone.json', Body = json.dumps(tone_analysis))\n    return tone_analysis\n\ndef print_tones(tones):\n    for tone in tones:\n        print(tone) ## note for self: update this and show table instead\n\ndef post_analysis(result):\n    for chunk in result.keys():\n        tone_categories = result[chunk]['document_tone']['tone_categories']\n        print('\\nchunk: ', chunk)\n        for tone_category in tone_categories:\n            print_tones(tone_category['tones']) #add table instead of prints\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "file_list = ['sample1-addresschange-positive.ogg',\n             'sample2-address-negative.ogg',\n             'sample3-shirt-return-weather-chitchat.ogg',\n             'sample4-angryblender-sportschitchat-recovery.ogg',\n             'sample5-calibration-toneandcontext.ogg',\n             'jfk_1961_0525_speech_to_put_man_on_moon.ogg',\n             'May 1 1969 Fred Rogers testifies before the Senate Subcommittee on Communications.ogg']\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "result = analyze_transcript(file_list[0])\npost_analysis(result) ## aggregrate tones then show histogram and then filter "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "for filename in file_list:\n    print(\"\\n\\nprocessing file: \", filename)\n    result = analyze_transcript(filename)\n    post_analysis(result) ## aggregrate tones then show histogram and then filter "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}