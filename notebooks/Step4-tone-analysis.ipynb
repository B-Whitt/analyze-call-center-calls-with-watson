{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "## Notebook 4 \u2013 Tone Analyzer \nhttps://www.ibm.com/watson/developercloud/tone-analyzer.html \nhttps://www.ibm.com/watson/developercloud/tone-analyzer/api/v3/ \n\nTone Analyzer service uses linguistic analysis to detect emotional and language tones in written text.\n\nIf you already have an IBM Cloud / Bluemix account login here https://console.bluemix.net/ \nIf you have not registered for IBM Cloud - you will need to Register for a Free account here https://www.ibm.com/watson/developer/\t\n\nTo create a TONE endpoint - https://console.bluemix.net/developer/watson/dashboard  LITE Plan for Tone is free\n\n### Tone Analyzer Signals\n\nA comma-separated list of tones for which the service is to return its analysis of the input. The indicated tones apply both to the full document and to individual sentences of the document. You can specify one or more of the following values:\n    emotion\n    language\n    social\n    \n2016-05-19: The service can return results for the following tone IDs of the different categories:\n        For the emotion category: \n            anger, \n            disgust, \n            fear, \n            joy, \n            sadness\n        For the language category: \n            analytical, \n            confident, \n            tentative\n        For the social category: \n            openness_big5, \n            conscientiousness_big5, \n            extraversion_big5, \n            agreeableness_big5,\n            emotional_range_big5\n         The service returns scores for all tones of a category, regardless of their values.\n\n    \n2017-09-21: The service can return results for the following tone IDs: anger, fear, joy, sadness, analytical, confident, and tentative. The service returns results only for tones whose scores meet a minimum threshold of 0.5.\n\nIf Tone Chat Score is used - these are the signals produced\n    sad\n    frustrated\n    satisfied\n    excited\n    polite\n    impolite\n    sympathetic\n\n\n## Install dependencies", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#imports.... Run this each time after restarting the Kernel\n#!pip install watson_developer_cloud\nimport watson_developer_cloud as watson\nimport json\nfrom botocore.client import Config\nimport ibm_boto3\n"
        }, 
        {
            "source": "### Create Watson Tone Analysis service\n\n\n### Add Credentials\n\nCopy paste the following snippet to next cell, and add your own set of crdentials there:\n\n```code\ncredentials_os = {\n    'IBM_API_KEY_ID': '',\n    'IAM_SERVICE_ID': '',\n    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n    'IBM_AUTH_ENDPOINT': 'https://iam.ng.bluemix.net/oidc/token',\n    'BUCKET': '',\n}\n\ncredentials_tone = {\n}\n\n```", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "source": "## Object storage client", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "client = ibm_boto3.client(service_name='s3', \n    ibm_api_key_id = credentials_os['IBM_API_KEY_ID'],\n    ibm_auth_endpoint = credentials_os['IBM_AUTH_ENDPOINT'],\n    config = Config(signature_version='oauth'),\n    endpoint_url = 'https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\n\n\n"
        }, 
        {
            "source": "### Tone\n\n- `process_text()` goes throught the text and fetch sentences and concatenate transcript based on chunk size\n- `analyze transcript()` calls tone analyzer endpoint and analyze the transcript\n- `post_anlysis()` shows tones and their score\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from watson_developer_cloud import ToneAnalyzerV3\n\ntone_analyzer = ToneAnalyzerV3(version = '2016-05-19',\n                               username = credentials_tone['username'],\n                               password = credentials_tone['password'])\n\n\nchunk_size=30\n\ndef chunk_transcript(transcript, chunk_size):\n    transcript = transcript.split(' ')\n    return [ transcript[i:i+chunk_size] for i in range(0, len(transcript), chunk_size) ] # chunking data\n    \n\ndef process_text(text):\n    transcript=''\n    for sentence in json.loads(text)['results']:\n        transcript = transcript + sentence['alternatives'][0]['transcript'] # concatenate sentences\n    transcript = chunk_transcript(transcript, chunk_size) # chunk the transcript\n    return transcript\n\n\ndef analyze_transcript(file_name):\n    transcript = client.get_object(Bucket = credentials_os['BUCKET'], Key = file_name)['Body']\n    transcript = transcript.read().decode(\"utf-8\")\n    tone_analysis={}\n    for chunk in process_text(transcript):\n        chunk = ' '.join(chunk)\n        tone_analysis[chunk] = tone_analyzer.tone(chunk, content_type='text/plain')\n    res=client.put_object(Bucket = credentials_os['BUCKET'], Key= file_name[0].split('_')[0]+'_tone.json', Body = json.dumps(tone_analysis))\n    return tone_analysis\n\ndef print_tones(tones):\n    for tone in tones:\n        print(tone) ## note for self: update this and show table instead\n\ndef post_analysis(result):\n    for chunk in result.keys():\n        tone_categories = result[chunk]['document_tone']['tone_categories']\n        print('\\nchunk: ', chunk)\n        for tone_category in tone_categories:\n            print_tones(tone_category['tones']) #add table instead of prints\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "text_files = [\n    'sample1-addresschange-positive_text.json',\n    'sample2-address-negative_text.json',\n    'sample3-shirt-return-weather-chitchat_text.json',\n    'sample4-angryblender-sportschitchat-recovery_text.json',\n    'sample5-calibration-toneandcontext_text.json'\n]\n\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "result = analyze_transcript(text_files[0])\npost_analysis(result)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "result = analyze_transcript(text_files[1])\npost_analysis(result)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}