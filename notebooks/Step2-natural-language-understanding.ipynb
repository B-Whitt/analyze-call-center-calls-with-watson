{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "\n## Notebook 2 \u2013 Natural Language Understanding (NLU)\nNLU analyzes text to extract meta-data from content such as concepts, entities, keywords, categories, relations and semantic roles.\nhttps://www.ibm.com/watson/services/natural-language-understanding/ \nhttps://www.ibm.com/watson/developercloud/natural-language-understanding/api/v1/  \n\n\n## Install dependencies\n\nPython\u2019s standard library is very extensive, offering a wide range of facilities. It contains built-in modules like JSON a lightweight data interchange format. https://docs.python.org/2/library/index.html and https://docs.python.org/2/library/json.html\n\nIBM Watson Developer Cloud has a Python client library to quickly get started with the various Watson APIs services. https://pypi.python.org/pypi/watson-developer-cloud\n\nUsing Python with IBM COS: Python support is provided through the Boto 3 library. The boto3 library provides complete access and can source credentials. The IBM COS endpoint must be specified when creating a service resource or low-level client as shown in documentation https://ibm-public-cos.github.io/crs-docs/python\n\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#imports.... Run this each time after restarting the Kernel\n#!pip install watson_developer_cloud\nimport watson_developer_cloud as watson\nimport json\nfrom botocore.client import Config\nimport ibm_boto3\n"
        }, 
        {
            "source": "### Create Watson Natural Language Understanding service\n\nFor more information on creating Watson services, see Notebook 1\n\n### Add Credentials\n\nCopy paste the following snippet to next cell, and add your own set of crdentials there:\n\n```code\ncredentials_os = {\n    'IBM_API_KEY_ID': '',\n    'IAM_SERVICE_ID': '',\n    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n    'IBM_AUTH_ENDPOINT': 'https://iam.ng.bluemix.net/oidc/token',\n    'BUCKET': '',\n}\n\ncredentials_nlu = {\n    \"url\": \"\",\n    \"username\": \"\",\n    \"password\": \"\"\n}\n\n```", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "source": "## Set-up Object storage", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# For more information on creating Watson services, see Notebook 1\n\nclient = ibm_boto3.client(service_name='s3', \n    ibm_api_key_id=credentials_os['IBM_API_KEY_ID'],\n    ibm_auth_endpoint=credentials_os['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\n"
        }, 
        {
            "source": "### NLU\n\n- `process_text()` goes throught the text and fetch sentences and concatenate transcript based on chunk size\n- `analyze transcript()` calls natural language understanding endpoint and analyze the transcripe\n- `post_analysis` processes the results and show insights based on response from NLU endpoint", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 45, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#NLU\n\nfrom watson_developer_cloud import NaturalLanguageUnderstandingV1\nfrom watson_developer_cloud.natural_language_understanding.features import (\n    v1 as Features)\n\nnatural_language_understanding = NaturalLanguageUnderstandingV1(\n    version = '2017-02-27',\n    username = credentials_nlu['username'],\n    password = credentials_nlu['password'])\n\nchunk_size=30 # This CHUNK size is used to disaggregate a transcript \n#e.g. in this case a 290 word transcript would have 10 chunks - 9 with 30 words and 1 with 20 words - approximates 'time domain' for this lab\n\ndef chunk_transcript(transcript, chunk_size):\n    transcript = transcript.split(' ')\n    return [ transcript[i:i+chunk_size] for i in range(0, len(transcript), chunk_size) ] # chunking data\n\ndef process_text(text):\n    transcript=''\n    for sentence in json.loads(text)['results']:\n        transcript = transcript + sentence['alternatives'][0]['transcript'] # concatenate sentences\n    transcript = chunk_transcript(transcript, chunk_size) # chunk the transcript\n    return transcript\n\n\ndef analyze_transcript(features, file_name):\n    streaming_body = client.get_object(Bucket = credentials_os['BUCKET'], Key=file_name)['Body']\n    transcript=streaming_body.read().decode(\"utf-8\")\n    nlu_analysis={}\n    for chunk in process_text(transcript):\n        chunk = ' '.join(chunk)\n        nlu_analysis[chunk] = natural_language_understanding.analyze(features, chunk, return_analyzed_text=True)\n    res=client.put_object(Bucket = credentials_os['BUCKET'], Key=file_name[0].split('_')[0]+'_tone', Body= json.dumps(nlu_analysis))\n    return nlu_analysis\n\ndef post_analysis(result):\n    for chunk in result.keys():\n        categories = result[chunk]['categories']\n        print('\\nchunk: ', chunk)\n        for category in categories:\n            print('label: ', category['label'], ', score: ', category['score']) #add table instead of prints\n"
        }, 
        {
            "execution_count": 46, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "text_files = ['sample1-addresschange-positive_text.json', 'sample2-address-negative_text.json', 'sample3-shirt-return-weather-chitchat_text.json', 'sample4-angryblender-sportschitchat-recovery_text.json', 'sample5-calibration-toneandcontext_text.json'] # we add audio files to COS pre-conference\nfeatures = {\"concepts\":{},\"entities\":{},\"keywords\":{},\"categories\":{},\"emotion\":{},\"sentiment\":{},\"semantic_roles\":{} }"
        }, 
        {
            "execution_count": 47, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\nchunk:  of said no other changes the only thing that I want to change is the address yes that's right yep very good yes thank you so much for help it\nlabel:  /shopping/resources/contests and freebies , score:  0.226511\nlabel:  /law, govt and politics/legal issues/legislation/tax laws , score:  0.16996\nlabel:  /business and industrial , score:  0.169616\n\nchunk:  is five five five one two one two yes that's me my old address is number one two three oak street my new address is five six seven pine street\nlabel:  /business and industrial , score:  0.22775\nlabel:  /real estate/apartments , score:  0.147439\nlabel:  /travel/tourist facilities/hotel , score:  0.129948\n\nchunk:  yes and the zip is nine zero two one zero yep that's right now the phone number stays the same that's right I would like to keep all the options\nlabel:  /technology and computing/consumer electronics/telephones/mobile phones , score:  0.165103\nlabel:  /travel/tourist destinations/mexico and central america , score:  0.142812\nlabel:  /business and industrial , score:  0.13298\n\nchunk:  good morning can you give me some help I'd like to change my address please my name is Ryan Smith I am from Sacramento California that's right my phone number\nlabel:  /technology and computing/hardware/computer , score:  0.798642\nlabel:  /finance/personal finance/lending/credit cards , score:  0.416438\nlabel:  /education/school , score:  0.215977\n\nchunk:  thanks have a good day bye bye \nlabel:  /art and entertainment/theatre , score:  0.969809\nlabel:  /art and entertainment/dance , score:  0.140806\nlabel:  /art and entertainment/music , score:  0.11456\n"
                }
            ], 
            "source": "result = analyze_transcript(features, text_files[0])\n\npost_analysis(result)\n"
        }, 
        {
            "execution_count": 48, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\nchunk:  I am yeah I want to change my address naw you know this is the third time this week I've had to call in to change a setting for some\nlabel:  /finance/personal finance/lending/credit cards , score:  0.580369\nlabel:  /technology and computing/hardware/computer , score:  0.312072\nlabel:  /business and industrial , score:  0.301379\n\nchunk:  okay yeah it's Bob Smith in Sacramento and my old addresses one twenty three oak street and my new address is four five six pine street yep that's right and\nlabel:  /business and industrial , score:  0.709109\nlabel:  /education/school , score:  0.223722\nlabel:  /family and parenting/children , score:  0.11288\n\nchunk:  me off all right Sir you're certain I'm not happy changed again all right yep that's correct all right okay bye bye \nlabel:  /art and entertainment/theatre , score:  0.314292\nlabel:  /science/mathematics/arithmetic , score:  0.158508\nlabel:  /art and entertainment/dance , score:  0.14672\n\nchunk:  is it is nine zero two one zero and I gotta tell you I'm getting pretty frustrated having to call you guys back this is %HESITATION it's kind of pissed\nlabel:  /art and entertainment/movies and tv/movies , score:  0.633057\nlabel:  /hobbies and interests/reading , score:  0.395072\nlabel:  /family and parenting/babies and toddlers , score:  0.0910402\n\nchunk:  reason you keep sending my mail to the old address I'm getting pretty frustrated so are can you just get it changed and hopefully you guys don't screwed up again\nlabel:  /technology and computing/internet technology/email , score:  0.354983\nlabel:  /law, govt and politics/immigration , score:  0.124926\nlabel:  /education/school , score:  0.111056\n"
                }
            ], 
            "source": "results = analyze_transcript(features, text_files[1])\n\npost_analysis(results)\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}