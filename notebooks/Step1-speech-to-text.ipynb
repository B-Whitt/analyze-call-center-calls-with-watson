{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Call Center Instrumentation & Analytics (CCIA)\n\n## Watson-Call-Center-Think18 Lab March 2015\n\nThis document provides guidance and background for a hands-on Python + IBM Watson lab being presented at an IBM Think2018 conference in March 2018, and for an IPython / Jupyter notebook and python code available for open source after the event.\n\nThe focus is Call Center Instrumentation and Analytics (CCIA) pattern.   The Notebook and information here seek to help organizations beginning to explore how to better understand the unstructured \"dark data\" that arises from phone calls to call centers. \n\n### Why is this useful?\nEnterprises spend more than $1 trillion on 250 billion customer service calls each year.  By using multiple IBM Watson \"signal services\" to extract signal from raw audio data; perform data analytics, clustering, unsupervised and machine learning, and visualizations, technical teams can use data understand patterns in call centers. KPI and ROI positive.\n\n### What is the process? And what Watson services are used?\nStep 1 - Speech to Text (STT) \u2013 Converts Raw Audio to Transcripts; \nStep 2 - Natural Language Understanding (NLU) - extracts features concepts, entities, keywords, categories/topics, sentiment and emotion; \nStep 3 - Natural Language Classifier (NLC) - is a user trained classification service, with user defined \u201cground truth\u201d that classifies text chunks; \nStep 4 - Tone Analyzer (Tone) \u2013 uses linguistic analysis to detect emotional and language tones in written text; \nStep 5 - Call Center Analytics \u2013 analyzes and visualizes the data signal to allow for interpretation of data and in cases, actionable insights; \n\n\n### Beginner Audience & Focus on Basics\n\u2022\tThis is a beginner lab intended to educate on the fundamentals of getting from data to insights with IBM Watson and open source tools \n\u2022\tAudience may include IT and operations teams curious about enriching unstructured data \u2013 the lab is NOT intended for sophisticated call center technologists \n\u2022\tLab/code does NOT purport to compete with expensive and sophisticated solutions already in market \n\u2022\tThe lab and code cover the basics \u2013 to educate on the fundamental plumbing and steps, to provide base for instrumentation \n\n### Success Metrics\nIf successful \u2013 the lab participants or notebook users will\n1.\tGain experience in using an IPython / Jupyter notebook\nhttps://ipython.org/notebook.html\n2.\tConnect to four Watson Developer Cloud \u2018signal service\u2019 APIs \nhttps://www.ibm.com/watson/developer/ \n3.\tConnect to IBM Cloud Object storage for data read and write \nhttps://www.ibm.com/cloud/object-storage \n4.\tUnderstand whether/how the tools and methods might benefit org\nhttps://github.com/mamoonraja/call-center-think18/tree/master/notebooks\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Notebook 1 \u2013 Speech to Text (STT) & First Contact\n## Install Python Dependencies\n\nPython\u2019s standard library is very extensive, offering a wide range of facilities.  It contains built-in modules like JSON a lightweight data interchange format.  https://docs.python.org/2/library/index.html and https://docs.python.org/2/library/json.html\n\nIBM Watson Developer Cloud has a Python client library to quickly get started with the various Watson APIs services.\nhttps://pypi.python.org/pypi/watson-developer-cloud\n\nUsing Python with IBM COS: Python support is provided through the Boto 3 library. The boto3 library provides complete access and can source credentials. The IBM COS endpoint must be specified when creating a service resource or low-level client as shown in documentation\nhttps://ibm-public-cos.github.io/crs-docs/python\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 160, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#imports.... Run this each time after restarting the Kernel\n!pip install watson_developer_cloud\nimport watson_developer_cloud as watson\nimport json\nfrom botocore.client import Config\nimport ibm_boto3\nimport requests\nfrom urllib.request import urlopen \n"
        }, 
        {
            "source": "## Set up Cloud Object Storage\nIBM Cloud Object Storage is a highly scalable cloud storage service, designed for high durability, resiliency and security. Store, manage and access your data via our self-service portal and RESTful APIs. Connect applications directly to Cloud Object Storage use other IBM Cloud Services with your data.  If creating separate of lab - go here: https://console.bluemix.net/catalog/services/cloud-object-storage to create one\n\nOnce Cloud object storage instance is created (pre-condition for this project), go to Cloud Object Storage dashboard: Login at http://ibm.com/cloud/ aka https://console.ng.bluemix.net/  and from Dashboard select your Cloud object storage instance, which will take you to service dashboard page.\n\n\n### Bucket name\nBuckets are created for you when you create project. From service dashboard page select `Buckets` from left navigation menu item, and get your bucket name and copy/paste bucket name below:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 172, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "credentials_os['BUCKET'] = '<bucket_name>' # copy bucket name from COS"
        }, 
        {
            "source": "### Credentials\nCredentials are also created for you when you create project. From service dashboard page select `Service Credentials` from left navigation menu item, and copy/paste the credentials below:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 173, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# For Cloud Object Storage\n\ncredentials_os = {\n}\n\n"
        }, 
        {
            "source": "### How to get audio files?\n\nYou can follow following sources to get audio files:\n    - https://github.com/mamoonraja/call-center-think18/tree/master/resources/audio_samples\n    - https://github.com/rustyoldrake/call_center_instrumentation_analytics/blob/master/CCIA_lab_test_audio.zip\n\nAudio files are alson uploaded to a cloud object storage instance for lab purposes, and you can get audio files by using read-only credentials provided by us. Copy/paste credentials below:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 199, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "credentials_audio_samples = {\n    \n}\n\ncredentials_audio_samples['BUCKET'] = 'audio-samples'"
        }, 
        {
            "source": "## Getting STT Credentials \nImporting Credentials \u2013 Each Watson signal service (STT, NLC, NLU and Tone) will require credentials - a username and password\nIf you already have an IBM Cloud / Bluemix account login here https://console.bluemix.net/ but if you have not yet registered for IBM Cloud - you will need to Register for a Free account here https://www.ibm.com/watson/developer/ registration takes less than 4 minutes and is free. More information here https://www.ibm.com/watson/developer-resources/ \n\nOnce logged in - go to https://console.bluemix.net/developer/watson/dashboard - browse services for SPEECH TO TEXT, and select Details, Create service from here https://console.bluemix.net/catalog/services/speech-to-text  - for free you can select LITE Plan \nLITE plan for STT \u201cgets you started with 100 minutes per month at no cost\u201d\n\nThe Username and Password (and URL) is found by clicking on service credentials and then \u201cview credential\u201d, and copy/paste credentials below: ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 202, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# For IBM Watson Speech to Text (STT) API\n\ncredentials_stt = {\n}\n"
        }, 
        {
            "execution_count": 203, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "source": "### Set up Object Storage", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 204, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def set_up_object_storage(credentials_object_storage):\n    endpoints = requests.get(credentials_object_storage['endpoints']).json()\n\n    iam_host = (endpoints['identity-endpoints']['iam-token'])\n    cos_host = (endpoints['service-endpoints']['cross-region']['us']['public']['us-geo'])\n\n    auth_endpoint = \"https://\" + iam_host + \"/oidc/token\"\n    service_endpoint = \"https://\" + cos_host\n\n\n    client = ibm_boto3.client(\n        's3',\n        ibm_api_key_id = credentials_object_storage['apikey'],\n        ibm_service_instance_id = credentials_object_storage['resource_instance_id'],\n        ibm_auth_endpoint = auth_endpoint,\n        config = Config(signature_version='oauth'),\n        endpoint_url = service_endpoint\n       )\n    return client\n\nclient = set_up_object_storage(credentials_os)\nclient_global = set_up_object_storage(credentials_audio_samples)\n\n"
        }, 
        {
            "source": "## Speect to Text \n\nFollowing cell has two methods:\n - `get_transcript()` calls speech to text enpoint and generates a text transcript for you for a sample audio file.\n - `analyze_sample()` gets the sample object from cloud storage, calls get_transcript to fetch the tranccript, and saves your transcript in cloud storage as `<file_name>_text.json`.\n \nOGG, WAV FLAC, L16, MP3, MPEG formats are options for the IBM Watson STT service.  For the lab we use OGG samples. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 205, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#STT\n\nimport json\nimport io\nfrom os.path import join, dirname\nfrom watson_developer_cloud import SpeechToTextV1\n\nspeech_to_text = SpeechToTextV1(\n    username = credentials_stt['username'],\n    password = credentials_stt['password'],\n    url = 'https://stream.watsonplatform.net/speech-to-text/api',\n)\n\n\n# OGG, WAV FLAC, L16, MP3, MPEG formats are options for the STT service \n# with Narrowband (generaly telco) and Broadband (e.g. higher quality USB mic) audio.  \n# For the LAB \u2013 OGG format was used for sample files in lab. Of other audio formats e.g. WAV - remember to change 'OGG' content_type='audio/ogg' in code below if you do.\n\n#get transcript Very basic one\ndef get_transcript(audio):\n    transcript = json.dumps(speech_to_text.recognize(audio, content_type='audio/ogg', timestamps=True,\n        word_confidence=True), indent=2)\n    return transcript\n\ndef download_file(path, filename):\n    url = path + filename\n    print(url)\n    r = requests.get(url, stream=True)\n    return r.content\n\ndef analyze_sample(sample):\n    streaming_body = client_global.get_object(Bucket = credentials_audio_samples['BUCKET'], Key=sample)['Body'] #http\n    audio = streaming_body.read()\n    text = get_transcript(audio)\n    client.put_object(Bucket = credentials_os['BUCKET'], Key = sample.split('.')[0] + '_text.json', Body = text)\n    return text\n\ndef visualize(transcript):\n    for result in json.loads(transcript)['results']:\n        print(result['alternatives'][0]['transcript'], result['alternatives'][0]['confidence'])    \n"
        }, 
        {
            "source": "## More about audio files\n\n`file_list` provides list of audio file in an array, each OGG file produces its own transcript.  \n\n    - Samples 1,2,3,4,5 are short - about 2 minutes \n    - Samples 6 and 7 are about 7 minutes (the STT SERVICE WILL NEED TIME TO PROCESS)\n\nFor longer files and transcription at scale: https://www.ibm.com/watson/developercloud/speech-to-text/api/v1/\n\n### WebSockets\nWebSockets includes a single method that establishes a persistent connection with the service over the WebSocket protocol.\n\n### Sessionless\nSessionless includes a method that provides a simple means of transcribing audio without the overhead of establishing and maintaining a session. Sessions provides methods that allow a client to maintain a long, multi-turn exchange, or session, with the service or to establish multiple parallel conversations with a particular instance of the service.\n\n### Asynchronous\nAsynchronous provides a non-blocking interface for transcribing audio. You can register a callback URL to be notified of job status and, optionally, results, or you can poll the service to learn job status and retrieve results manually. Longer (e.g. 1 hour) audio files may justify using asynchronous method, and a real time a sessions method (both defined below)\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 206, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "file_list = ['sample1-addresschange-positive.ogg',\n             'sample2-address-negative.ogg',\n             'sample3-shirt-return-weather-chitchat.ogg',\n             'sample4-angryblender-sportschitchat-recovery.ogg',\n             'sample5-calibration-toneandcontext.ogg',\n             'jfk_1961_0525_speech_to_put_man_on_moon.ogg',\n             'May 1 1969 Fred Rogers testifies before the Senate Subcommittee on Communications.ogg']\n"
        }, 
        {
            "source": "## Transcription Test - Point to first file in list (position 0) and analyze ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 207, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "good morning  0.995\ncan you give me some help I'd like to change my address please  0.999\nmy name is Ryan Smith  0.972\nI am from Sacramento California  0.969\nthat's right  0.996\nmy phone number is five five five one two one two  0.839\nyes that's me  0.997\nmy old address is number one two three oak street  0.965\nmy new address is five six seven pine street  0.869\nyes and the zip is nine zero two one zero  0.921\nyep that's right  0.89\nnow the phone number stays the same  0.808\nthat's right I would like to keep all the options of said no other changes the only thing that I want to change is the address  0.944\nyes that's right  0.995\nyep  0.583\nvery good yes thank you so much for help  0.903\nit  0.419\nthanks have a good day bye bye  0.994\n"
                }
            ], 
            "source": "# TRANSCRIBE \u2013 this is where STT receives the OGG files provided and returns text to TRANSCRIPT\n# this is a test of ONE transcription in the list - place '0' - may take a minute\ntranscript = analyze_sample(file_list[0])\nvisualize(transcript)"
        }, 
        {
            "execution_count": 208, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "now Mister Rogers is certainly one of the best things that ever happened to public television and his people audio award is testament to that fact  0.925\nwe in public television are proud of Fred Rogers and I'm proud to present Mister Rogers to you now from Iraq did you get the phone  0.766\nsenator past story  0.699\nthis is a philosophical statement and would take about ten minutes to read so I'll not do that  0.977\nof  0.77\none of the first things that a child learns in a healthy family is traps  0.888\nand I trust what you have said that you will read this it's very important to me I care deeply about children  0.945\nmy first will make you happy if you read it  0.764\nI'd just like to talk about it if all right of my first children's programming was on WQAD fifteen years ago  0.874\nand its budget was thirty dollars  0.99\nnow with the help of  1.0\nthe Sears Roebuck foundation and national educational television as well as  0.985\nall of the affiliated stations each station Hayes to show our program  0.924\nit's a unique kind of finding an educational television  0.836\nwith this help now our program has a budget of six thousand dollars  0.948\nit may sound like quite a difference but six thousand dollars pays for less than two minutes of cartoons  0.909\ntwo minutes of animated  0.999\nwhat I sometimes say bombardment I'm very much concerned as I know you are  0.944\nabout what's being delivered to our children in this country  0.994\nand I've worked in the field of child development for six years now trying to understand the inner needs of children  0.997\nwe deal with such things as  1.0\nas the inner drama of child  0.86\nwe don't have to bop somebody over the head to make him  0.926\nto to make drama on the screen  0.866\nwe deal with such things as getting a hair cut  0.945\nor the feelings about brothers and sisters and the kind of anger that arises in simple family situations and we speak to it constructively along the program is it it's a half hour every day  0.868\nmost channels schedule it in in the noon time as well as in the evening  0.838\nof W. ETA here has scheduled in the late afternoon  0.725\ncould we get a copy of this so that we can see  0.864\nmaybe not today but I'd like to see the program I'd like very much for you like to see the program itself or any one of them say  0.883\nwe we made a hundred programs for E. and the eastern educational network and then when the money ran out people in Boston and Pittsburgh and Chicago all came to the fore and said we've got to have more of this neighborhood expression of care  0.957\nand this is what  1.0\nthis is what I give I give an expression of care every day to each child  0.84\nhelp him realize that he is unique  0.885\nI am the program by saying you've made this day a special day by day just you're being you  0.952\nthere's no person in the whole world like you  0.91\nand I like you just the way you are  0.917\nand I feel that if we in public television can only  0.975\nmake it clear that feeling  0.927\nour mention uncle and manageable we will have done a great service  0.888\nfor mental health  0.972\nwell I think that it's much more dramatic that two men could be working out their feelings of anger  0.898\nmuch more dramatic than showing something of gun fire  0.869\nI'm constantly concerned about what our children are seen  0.922\nand for fifteen years I have tried in this country and Canada to present what I feel is a meaningful expression of care  0.99\ndo you have an a rating  0.497\nI'm a hoax yes and I do all the pop ups and I write all the music and I write all the screen I'm supposed to be a pretty tough guy in this the first time I've had goose bumps for the last two days  0.833\nwell I'm grateful not only for your goose bumps but for your interests in in our kind of communication  0.841\ncould I tell you the words of one of the songs which I feel is very important is  0.897\nthis has to do with that good feeling of control which I feel that the children need to know it's there and it starts out what do you do with the man that you feel and that first line came straight from a child I work with children doing pop ups in in very personal communication with small groups what do you do with the mad that you feel when you feel so mad you could buy  0.928\nwhen the whole wide world seems oh so wrong and nothing you do seems very right  0.977\nwhat do you do do you hunt your bag D. a pound some clay or some dough  0.702\ndo you round up friends for a game of tag or see how fast you go  0.898\nit's great to be able to stop  0.989\nwhen you plan the thing that's wrong  0.759\nand be able to do something else instead and think this song I can stop when I want to can stop when I wish can stop stop stop anytime  0.904\nand what a good feeling to feel like this and know that the feeling is really mine know that there's something deep inside that helps us become what we can  0.968\nfor a girl can be some day a lady  0.91\nand the boy can be some day a man I think it's wonderful  0.874\nI think it's wonderful  0.811\n%HESITATION looks like you just in the twenty million dollars  0.666\n"
                }
            ], 
            "source": "# Testing position [6] - which is the LONGER OGG file - 7th position Fred Rogers - just under 7 minutes\n\ntranscript = analyze_sample(file_list[6])\nvisualize(transcript)\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}